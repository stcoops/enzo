
#  Enzo

**Enzo** is a locally hosted AI application built with [Textual](https://textual.textualize.io/) in Python. Designed for speed, simplicity, and full local control, Enzo offers a sleek terminal UI for AI interactions without relying on remote servers or cloud services.

>  **Work in Progress**  
> Enzo is currently under active development and not ready for public release.

---

## Features (Planned & In Progress)

-  Textual-based modern TUI (Text User Interface)
-  Local AI inference (no external API calls)
-  Prompt management and history
-  Local data storage


---

## Current To-Do list:
- [x] Core AI integration
- [x] Let Ollama Streaming = True
- [x] Prompt history & management
- [ ] Menu functionality
- [ ] Update website
- [x] Fix unclosed Client session
- [x] Make Load + App screens so no pause after load
- [ ] Enhanced error handling & logging
- [ ] Rename files & simple cleanup.
- [ ] Configurable themes
- [ ] Installer packaging (Windows, macOS, Linux)

## Current Flaws:
(see To-Do list)
- [ ] Error Handling
- [ ] Lack of Menu
- [ ] Load Speeds

- [x] Unclosed Client Session bug
- [x] TTS bigChunk broken (Removed entirely)
- [x] Ollama streaming can intersect itself. flag needed
- [x] Playsound an absolute mess (fixed but not much better)
- [x] Messy Codebase
---

## ü§ù Contributing

Development is currently closed while core systems are being established.  
Feedback and ideas are welcome via issues and discussions, but pull requests will be considered after initial milestones are complete.

---

## üìÑ License

This project will be licensed under the MIT License once released.

---

## üé® Preview

![Dashboard](https://github.com/stcoops/enzo/blob/main/site/images/Enzo.png)

---

**Enzo** ‚Äî your AI, your terminal, your rules.  
Built with ‚ù§Ô∏è using [Textual](https://textual.textualize.io/)
